import pandas as pd

def clean_dataset(df, drop_duplicates=True, fill_missing=None):
    """
    Clean a pandas DataFrame by removing duplicates and handling missing values.
    
    Args:
        df (pd.DataFrame): Input DataFrame to clean.
        drop_duplicates (bool): Whether to drop duplicate rows. Default is True.
        fill_missing (str or dict): Method to fill missing values. 
            Options: 'mean', 'median', 'mode', or a dictionary of column:value pairs.
            If None, missing values are not filled.
    
    Returns:
        pd.DataFrame: Cleaned DataFrame.
    """
    cleaned_df = df.copy()
    
    if drop_duplicates:
        cleaned_df = cleaned_df.drop_duplicates()
        print(f"Removed {len(df) - len(cleaned_df)} duplicate rows.")
    
    if fill_missing is not None:
        if fill_missing == 'mean':
            cleaned_df = cleaned_df.fillna(cleaned_df.mean(numeric_only=True))
        elif fill_missing == 'median':
            cleaned_df = cleaned_df.fillna(cleaned_df.median(numeric_only=True))
        elif fill_missing == 'mode':
            cleaned_df = cleaned_df.fillna(cleaned_df.mode().iloc[0])
        elif isinstance(fill_missing, dict):
            cleaned_df = cleaned_df.fillna(fill_missing)
        else:
            raise ValueError("Invalid fill_missing option. Use 'mean', 'median', 'mode', or a dictionary.")
        
        missing_count = df.isnull().sum().sum()
        if missing_count > 0:
            print(f"Filled {missing_count} missing values using method: {fill_missing}")
    
    return cleaned_df

def validate_data(df, required_columns=None, numeric_columns=None):
    """
    Validate the structure and content of a DataFrame.
    
    Args:
        df (pd.DataFrame): DataFrame to validate.
        required_columns (list): List of column names that must be present.
        numeric_columns (list): List of column names that should be numeric.
    
    Returns:
        dict: Dictionary containing validation results.
    """
    validation_results = {
        'is_valid': True,
        'missing_columns': [],
        'non_numeric_columns': [],
        'row_count': len(df),
        'column_count': len(df.columns)
    }
    
    if required_columns:
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            validation_results['missing_columns'] = missing
            validation_results['is_valid'] = False
    
    if numeric_columns:
        non_numeric = []
        for col in numeric_columns:
            if col in df.columns:
                if not pd.api.types.is_numeric_dtype(df[col]):
                    non_numeric.append(col)
        if non_numeric:
            validation_results['non_numeric_columns'] = non_numeric
            validation_results['is_valid'] = False
    
    return validation_resultsimport numpy as np
import pandas as pd
from scipy import stats

class DataCleaner:
    def __init__(self, df):
        self.df = df.copy()
        self.numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    
    def remove_outliers_iqr(self, columns=None, factor=1.5):
        if columns is None:
            columns = self.numeric_columns
        
        clean_df = self.df.copy()
        for col in columns:
            if col in self.numeric_columns:
                Q1 = clean_df[col].quantile(0.25)
                Q3 = clean_df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - factor * IQR
                upper_bound = Q3 + factor * IQR
                clean_df = clean_df[(clean_df[col] >= lower_bound) & (clean_df[col] <= upper_bound)]
        return clean_df
    
    def normalize_data(self, columns=None, method='zscore'):
        if columns is None:
            columns = self.numeric_columns
        
        normalized_df = self.df.copy()
        for col in columns:
            if col in self.numeric_columns:
                if method == 'zscore':
                    normalized_df[col] = stats.zscore(normalized_df[col])
                elif method == 'minmax':
                    min_val = normalized_df[col].min()
                    max_val = normalized_df[col].max()
                    normalized_df[col] = (normalized_df[col] - min_val) / (max_val - min_val)
                elif method == 'robust':
                    median = normalized_df[col].median()
                    iqr = normalized_df[col].quantile(0.75) - normalized_df[col].quantile(0.25)
                    normalized_df[col] = (normalized_df[col] - median) / iqr
        return normalized_df
    
    def fill_missing(self, columns=None, strategy='mean'):
        if columns is None:
            columns = self.numeric_columns
        
        filled_df = self.df.copy()
        for col in columns:
            if filled_df[col].isnull().any():
                if strategy == 'mean':
                    fill_value = filled_df[col].mean()
                elif strategy == 'median':
                    fill_value = filled_df[col].median()
                elif strategy == 'mode':
                    fill_value = filled_df[col].mode()[0]
                elif strategy == 'constant':
                    fill_value = 0
                filled_df[col] = filled_df[col].fillna(fill_value)
        return filled_df
    
    def get_summary(self):
        summary = {
            'original_shape': self.df.shape,
            'numeric_columns': self.numeric_columns,
            'missing_values': self.df.isnull().sum().to_dict(),
            'data_types': self.df.dtypes.to_dict()
        }
        return summary

def process_dataset(file_path, output_path=None):
    df = pd.read_csv(file_path)
    cleaner = DataCleaner(df)
    
    print("Dataset Summary:")
    print(f"Original shape: {cleaner.get_summary()['original_shape']}")
    print(f"Numeric columns: {cleaner.get_summary()['numeric_columns']}")
    
    cleaned_df = cleaner.fill_missing(strategy='median')
    cleaned_df = cleaner.remove_outliers_iqr()
    normalized_df = cleaner.normalize_data(method='zscore')
    
    if output_path:
        normalized_df.to_csv(output_path, index=False)
        print(f"Processed data saved to: {output_path}")
    
    return normalized_df

if __name__ == "__main__":
    sample_data = pd.DataFrame({
        'feature_a': np.random.normal(100, 15, 1000),
        'feature_b': np.random.exponential(50, 1000),
        'feature_c': np.random.randint(1, 100, 1000),
        'category': np.random.choice(['A', 'B', 'C'], 1000)
    })
    
    sample_data.iloc[10:20, 0] = np.nan
    sample_data.iloc[50:60, 1] = np.nan
    
    cleaner = DataCleaner(sample_data)
    result = cleaner.fill_missing().remove_outliers_iqr().normalize_data()
    print(f"Processed data shape: {result.shape}")
    print("Processing complete.")